---
layout: post
title: deeplearning.ai深度学习课程 第一阶段第一周
categories: coding
tag: 机器学习, 深度学习
---

吴恩达的新公司deeplearning.ai发布的第一个产品是coursera上新的深度学习公开课，看来他还是喜欢当老师，试听了后，决定当一名正式学生完成这一系列的课程(旁听的无法做作业和考试)。目前的价格是49美金包月（如果我理解没错的话，这包括了coursera上所有的课程），按照我现在的时间安排和学习速度，2~3周时间差不多了。相比之前的机器学习课程，编程语言从matlab换成了python，身为程序员感觉比较亲切友好。

这次准备除了学完课程，做完作业拿到证书之外，还同步做一些笔记，但是时间关系，笔记将不是完整记录性质的，主要记录一下老师讲课的思路，以及自己的理解和疑点，完善部分推导过程。这次课程开发了pptx下载，因此笔记以pptx截屏加评注的方式进行。

![幻灯片1](..\img\What-is-a-NN\幻灯片1.JPG)

神经网络的概念，虽然我也算比较熟悉了，但是老师切入的角度还是很好很直观。

![幻灯片2](..\img\What-is-a-NN\幻灯片2.JPG)

老师举了一个房价预测的例子，使用一个ReLU函数，虽然很简单，但是可以视为一个神经元。

![幻灯片3](..\img\What-is-a-NN\幻灯片3.JPG)

不同的输入要素结合，在预测房价的过程中结合成不同的意义，比如家庭大小，学区质量之类的，这些意义构成了中间要素，或者说这些神经元的输入成为了更高一级别概念的输入。

![幻灯片4](..\img\What-is-a-NN_\幻灯片4.JPG)

我的疑问是，这些中间层的意义似乎不是总是存在的。神经网络被诟病的点之一就是它很难给人直观的解释，我想，这或许也是神经网络的意义所在，它能够发现一些人们不知道无法理解的中间因素，最终综合出结论。对于工业界尤其是商界而言，解释可能没有带来真金白银的计算结果那么重要。



![幻灯片1](..\img\C1W1L03\幻灯片1.JPG)

这门课的特点是不需要太对的背景知识，所以老师还介绍了监督学习的概念。

![幻灯片2](..\img\C1W1L03\幻灯片2.JPG)

在监督学习中，搞清楚输入输出是什么非常重要，只有这样，才能去选择合适的模型。一般的结构化数据预测使用普通NN，图像识别使用CNN，语音识别和机器翻译使用RNN，一些更复杂的问题比如自动驾驶需要使用更加定制化的混合的NN。

![幻灯片3](..\img\C1W1L03\幻灯片3.JPG)

这三种神经网络都有典型的结构图，我对后两种以前都只知道皮毛。

![幻灯片4](..\img\C1W1L03\幻灯片4.JPG)

结构化数据和非结构化数据的区别，通俗一点讲，就是结构化数据本来就是一张表，一般来说可以用excel之类的软件直观的查看，而非结构化数据则是其他的一些东西，比如图像、语音、文本信息之类的。

![幻灯片1](..\img\C1W1L04\幻灯片1.JPG)

接下来探讨了为什么深度学习突然火起来来了，其实这门技术并不是那么新。

![幻灯片2](..\img\C1W1L04\幻灯片2.JPG)

第一个原因就是大数据时代的来临，神经网络是参数极多的机器学习算法，规模越大，参数越多，则大数据带给它的好处就越明显，而在小数据集中，类似SVM的机器学习算法其实更有优势。

![幻灯片3](..\img\C1W1L04\幻灯片3.JPG)

第二个原因是计算能力的增强，这得益于摩尔定律和大规模计算的兴起，第三个原因才是算法的革新，比如计算量更小的ReLU函数替代Sigmoid函数。

在机器学习中，试验是一个很重要的环节，计算速度的加快，实际上使得试验周期大大缩短，促进了新的算法的产生。

![幻灯片1](..\img\C1W1L05\幻灯片1.JPG)

下面是课程的提纲，非常清晰。

![幻灯片2](..\img\C1W1L05\幻灯片2.JPG)



![幻灯片3](..\img\C1W1L05\幻灯片3.JPG)

最后老师还采访了Geoffrey Hinton，实话说，大神间的对话很多我没听懂，不过能感受到那种学术热情。大神还说，不要读过多的文献，而是要去验证自己的想法，不过什么是过多，小白听了千万不要上当才对。有的人的问题是读得太多，大部人的问题可能还是读得太少。